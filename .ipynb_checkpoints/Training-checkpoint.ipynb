{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0aa7e2-2577-4396-b708-4c1f73bef573",
   "metadata": {},
   "source": [
    "# Training Session\n",
    "This section tries to do the following tasks:\n",
    "* Train a classification model on your system\n",
    "* Convert the Trained model into Keras\n",
    "* Convert the Trained model into ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56346f-ab5e-426a-9e79-09fa94c2f2d4",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcc2528-8f67-4119-8f9b-f2e19ed23015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102876bb-583f-4d6b-a5bd-d23a785f070f",
   "metadata": {},
   "source": [
    "#### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b324e2b-fbde-4d89-9421-fb13745a859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "image_exts = ['jpg', 'jpeg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc235f9-80f6-4b38-898f-679d76ef547d",
   "metadata": {},
   "source": [
    "#### The following Cell detect images with wrong extentions. These images could make problems during training the network. \n",
    "\n",
    "There is a file created by Mac called .DS_Store. Next cell will check each file and ignore it whenever it sees it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9ffa1-b93b-43a7-9c84-9783c9a5e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the data directory\n",
    "for image_class in os.listdir(data_dir): \n",
    "    if image_class == '.DS_Store':\n",
    "        continue\n",
    "    # Enter images directories\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        if image == '.DS_Store':\n",
    "            continue\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a6b8a-2c28-4cd4-aabf-570aac26ba3b",
   "metadata": {},
   "source": [
    "#### Next step is to load data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61ff54-d874-4c0d-8b05-de10906c1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81f698-99ed-4359-b547-30dd81e105df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554dd4dc-a287-46ca-af57-7cb03e7e7262",
   "metadata": {},
   "source": [
    "#### Scale and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1ce04-f47c-4a32-bbc7-66d1fec028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "data.as_numpy_iterator().next()\n",
    "train_size = int(len(data)*.5)\n",
    "val_size = int(len(data)*.3)\n",
    "test_size = int(len(data)*.2)\n",
    "print(\"Train size\", train_size)\n",
    "print(\"Validation\", val_size)\n",
    "print(\"Test size\", test_size)\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012956e-0529-4bd7-93df-685499608ded",
   "metadata": {},
   "source": [
    "#### Build deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855b259-b33d-4000-b74e-a9ae574abd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activations.relu))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activations.relu))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activations.relu))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activations.relu))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activations.relu))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d07ea-f8f2-452b-bc50-65b4555010c5",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb7cc3-31bc-4a63-9c24-a91d1cadcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "hist = model.fit(train, epochs=300, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3891df-2c46-4a2a-9704-d863ae2abc3b",
   "metadata": {},
   "source": [
    "#### Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bbcaf-1286-4897-9426-c9d6c46c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a5ed8-cacf-400a-899c-aa8c7e77e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab93369-1b80-45ad-b944-12b5faf2d37f",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535d691-9c36-4a12-acab-8bdb5119bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3b6a4-2f2f-4093-9f05-c2dc92ed54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70458a9d-0f46-4119-8c53-1282dcd8f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14344f8a-9e2a-4f3a-917e-3f81bb506be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ff7e1-1f44-465e-8033-b0e299716a95",
   "metadata": {},
   "source": [
    "#### Save and Inference the Model in Keras format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d75dfd-a4df-4476-9794-70d9293a5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model in keras (.h5)\n",
    "from tensorflow.keras.models import load_model\n",
    "model.save(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4bf0e-7c0f-421a-a0dc-5b67c412546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference the Keras model\n",
    "new_model = load_model('imageclassifier.h5')\n",
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8641e-8a80-49c7-88fd-bcbd957f9097",
   "metadata": {},
   "source": [
    "#### Save the Model in PB format and Convert it into ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68a32e-7d1d-46f5-8847-f9e8ffd9f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in the saved_model format\n",
    "SAVED_MODEL_DIR=\"./models/native_saved_model/\"\n",
    "model.save(SAVED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99042606-ac66-4b2b-8c44-1de57d65fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trained model into ONNX\n",
    "!python -m tf2onnx.convert --saved-model \"./models/native_saved_model\" --output model.onnx --opset 11 --verbose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
